from flask import Flask, render_template, jsonify, request
from flask_cors import CORS
import feedparser
import requests
from datetime import datetime, timedelta
# from googletrans import Translator  # Kikomment√°lva - AI-val ford√≠tunk
import hashlib
import os
from dotenv import load_dotenv
import schedule
import threading
import time
from ai_processor import GovernmentEconomicAnalyzer
from database import init_database, is_database_available
from database_manager import db_manager
from flask import send_file
import tempfile
try:
    import pdfkit
    PDF_GENERATOR = 'pdfkit'
except ImportError:
    pdfkit = None
    PDF_GENERATOR = None
    
# WeasyPrint-et kikapcsoljuk production-ben
HTML = None
    
if not pdfkit:
    print("‚ö†Ô∏è PDF export nem el√©rhet≈ë production k√∂rnyezetben")

load_dotenv()

app = Flask(__name__)
CORS(app)

# Teszt m√≥d a gyorsabb fejleszt√©shez
TEST_MODE = os.getenv('TEST_MODE', 'false').lower() == 'true'

# Glob√°lis v√°ltoz√≥k a h√≠rek t√°rol√°s√°ra
newsletter_data = {
    'articles': [],
    'executive_briefing': '',
    'last_update': None,
    'update_count': 0,
    'processing_status': 'idle'
}

# Database inicializ√°l√°sa
if init_database():
    print("‚úÖ PostgreSQL adatb√°zis k√©sz")
else:
    print("‚ö†Ô∏è PostgreSQL nem el√©rhet≈ë - mem√≥ria m√≥dban fut")

# AI elemz≈ë inicializ√°l√°sa
ai_analyzer = GovernmentEconomicAnalyzer()

# Gazdas√°gi RSS forr√°sok (angol nyelv≈±)
ECONOMIC_SOURCES = [
    # PR√âMIUM FORR√ÅSOK
    {
        'name': 'Bloomberg Markets',
        'url': 'https://feeds.bloomberg.com/markets/news.rss',
        'category': 'Piacok'
    },
    {
        'name': 'Bloomberg Politics',
        'url': 'https://feeds.bloomberg.com/politics/news.rss',
        'category': 'Gazdas√°gpolitika'
    },
    {
        'name': 'Bloomberg Technology',
        'url': 'https://feeds.bloomberg.com/technology/news.rss',
        'category': 'Tech & Gazdas√°g'
    },
    {
        'name': 'Financial Times',
        'url': 'https://www.ft.com/rss/home',
        'category': '√Åltal√°nos gazdas√°g'
    },
    {
        'name': 'The Economist - Finance',
        'url': 'https://www.economist.com/finance-and-economics/rss.xml',
        'category': 'Elemz√©sek'
    },
    {
        'name': 'The Economist - Business',
        'url': 'https://www.economist.com/business/rss.xml',
        'category': '√úzleti elemz√©sek'
    },
    {
        'name': 'Reuters Business',
        'url': 'https://feeds.reuters.com/reuters/businessNews',
        'category': '√úzleti h√≠rek'
    },
    {
        'name': 'Wall Street Journal',
        'url': 'https://feeds.wsj.com/rss/RSSWorldNews.xml',
        'category': 'P√©nz√ºgyek'
    },
    {
        'name': 'MarketWatch',
        'url': 'https://feeds.content.dowjones.io/public/rss/mw_topstories',
        'category': 'T≈ëzsde'
    },
    {
        'name': 'CNBC',
        'url': 'https://www.cnbc.com/id/100003114/device/rss/rss.html',
        'category': 'T≈ëzsde'
    },
    {
        'name': 'Business Insider',
        'url': 'https://markets.businessinsider.com/rss/news',
        'category': 'Piacok & √úzlet'
    },
    {
        'name': 'BBC Business',
        'url': 'http://feeds.bbci.co.uk/news/business/rss.xml',
        'category': 'Glob√°lis gazdas√°g'
    },
    # ELEMZ√âSEK & THINK TANK
    {
        'name': 'Investopedia - V√°llalati',
        'url': 'https://www.investopedia.com/feedbuilder/feed/getfeed?feedName=rss_headline&categoryName=company-news',
        'category': 'V√°llalati h√≠rek'
    },
    {
        'name': 'Investopedia - Piacok',
        'url': 'https://www.investopedia.com/feedbuilder/feed/getfeed?feedName=rss_headline&categoryName=markets-news',
        'category': 'Piaci h√≠rek'
    },
    {
        'name': 'Economic Policy Institute',
        'url': 'http://feeds.feedburner.com/epi',
        'category': 'Gazdas√°gpolitika'
    },
    {
        'name': 'Federal Reserve FRED',
        'url': 'https://fredblog.stlouisfed.org/feed/',
        'category': 'Fed elemz√©sek'
    },
    {
        'name': 'Congressional Budget Office',
        'url': 'https://www.cbo.gov/publications/all/rss.xml',
        'category': 'K√∂lts√©gvet√©s'
    },
    # BEFOLY√ÅSOS BLOGOK
    {
        'name': 'Calculated Risk',
        'url': 'http://feeds.feedburner.com/calculatedrisk',
        'category': 'Makrogazdas√°g'
    },
    {
        'name': 'Marginal Revolution',
        'url': 'http://feeds.feedburner.com/marginalrevolution',
        'category': 'K√∂zgazdas√°gtan'
    },
    {
        'name': 'Financial Samurai',
        'url': 'https://financialsamurai.com/feed/',
        'category': 'P√©nz√ºgyi tan√°csok'
    },
    {
        'name': 'Zero Hedge',
        'url': 'http://feeds.feedburner.com/zerohedge/feed',
        'category': 'Alternat√≠v elemz√©s'
    }
]

# translator = Translator()  # Kikomment√°lva - AI-val ford√≠tunk

def generate_article_id(title, source):
    """Egyedi azonos√≠t√≥ gener√°l√°sa"""
    content = f"{title}-{source}".encode('utf-8')
    return hashlib.md5(content).hexdigest()[:12]

def translate_text(text, max_retries=3):
    """Sz√∂veg ford√≠t√°sa angol->magyar AI-val"""
    if not text:
        return text
    
    # Haszn√°ljuk a Gemini API-t a ford√≠t√°shoz
    try:
        if ai_analyzer.gemini_model:
            prompt = f"Translate to Hungarian (output ONLY the Hungarian translation, no explanations): {text}"
            response = ai_analyzer.gemini_model.generate_content(prompt)
            # Clean up response - remove any THOUGHT sections or extra text
            result = response.text.strip()
            if "THOUGHT:" in result:
                # Extract only the translation part
                lines = result.split('\n')
                for line in lines:
                    if line.strip() and not line.startswith('THOUGHT:') and not line.startswith('*'):
                        return line.strip()
            return result
        else:
            # Ha nincs Gemini API, adjuk vissza az angol sz√∂veget
            return text
    except Exception as e:
        print(f"Ford√≠t√°si hiba: {e}")
        return text

def fetch_and_process_news():
    """H√≠rek lek√©r√©se √©s feldolgoz√°sa korm√°nyzati elemz√©ssel"""
    # Ellenorizz√ºk, hogy nem fut-e m√°r
    if newsletter_data.get('processing_status') == 'processing':
        print("‚ö†Ô∏è Feldolgoz√°s m√°r folyamatban...")
        return
    
    newsletter_data['processing_status'] = 'processing'
    print(f"\n{'='*60}")
    print(f"üèõÔ∏è KORM√ÅNYZATI GAZDAS√ÅGI H√çRLEV√âL FRISS√çT√âSE")
    print(f"Id≈ëpont: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")
    
    all_articles = []
    
    # RSS forr√°sok feldolgoz√°sa
    for source in ECONOMIC_SOURCES:
        try:
            print(f"üì° Lek√©r√©s: {source['name']}")
            feed = feedparser.parse(source['url'])
            
            for entry in feed.entries[:3]:  # Max 3 cikk forr√°sonk√©nt a min≈ës√©g miatt
                # Alapadatok kinyer√©se
                title = entry.get('title', 'Nincs c√≠m')
                description = entry.get('summary', entry.get('description', ''))
                link = entry.get('link', '')
                
                # Publik√°l√°si id≈ë
                pub_date = None
                if hasattr(entry, 'published_parsed'):
                    pub_date = datetime(*entry.published_parsed[:6])
                elif hasattr(entry, 'updated_parsed'):
                    pub_date = datetime(*entry.updated_parsed[:6])
                else:
                    pub_date = datetime.now()
                
                # Csak az elm√∫lt 48 √≥ra h√≠rei (korm√°nyzati elemz√©shez b≈ëvebb id≈ëablak)
                if datetime.now() - pub_date > timedelta(days=2):
                    continue
                
                # Egyel≈ëre nem ford√≠tunk - t√∫l lass√∫ a bet√∂lt√©shez
                translated_title = title  # translate_text(title)
                translated_description = description  # translate_text(description)
                
                article = {
                    'id': generate_article_id(title, source['name']),
                    'original_title': title,
                    'title': translated_title,
                    'original_description': description,
                    'description': translated_description,
                    'source': source['name'],
                    'category': source['category'],
                    'link': link,
                    'pub_date': pub_date.isoformat(),
                    'timestamp': datetime.now().isoformat()
                }
                
                all_articles.append(article)
                
        except Exception as e:
            print(f"‚ùå Hiba {source['name']} feldolgoz√°sakor: {e}")
            continue
    
    print(f"\nüìä √ñsszesen {len(all_articles)} cikk √∂sszegy≈±jtve")
    
    # AI elemz√©s csak ha vannak cikkek
    if all_articles:
        print(f"\nü§ñ Korm√°nyzati AI elemz√©s ind√≠t√°sa...")
        processed_articles, executive_briefing = ai_analyzer.process_articles_for_government(all_articles)
        
        if not is_database_available():
            # Fallback: mem√≥ria m√≥d
            formatted_articles = [
                ai_analyzer.format_article_for_display(article)
                for article in processed_articles[:20]
            ]
            newsletter_data['articles'] = formatted_articles
            newsletter_data['executive_briefing'] = executive_briefing or "‚ö†Ô∏è Vezet≈ëi √∂sszefoglal√≥ nem el√©rhet≈ë"
    else:
        if not is_database_available():
            newsletter_data['articles'] = []
            newsletter_data['executive_briefing'] = "Nincs feldolgozhat√≥ cikk."
    
    newsletter_data['last_update'] = datetime.now().isoformat()
    newsletter_data['update_count'] += 1
    newsletter_data['processing_status'] = 'completed'
    
    print(f"\n‚úÖ Friss√≠t√©s k√©sz! Feldolgozott cikkek: {len(newsletter_data['articles'])}")
    print(f"{'='*60}\n")

def run_scheduler():
    """√útemez≈ë futtat√°sa h√°tt√©rsz√°lon"""
    while True:
        schedule.run_pending()
        time.sleep(60)

# √útemezett feladatok be√°ll√≠t√°sa - K√âT K√úL√ñN CIKLUS
def fetch_rss_only():
    """Csak RSS h√≠rek lek√©r√©se elemz√©s n√©lk√ºl (30 percenk√©nt)"""
    print(f"\nüì∞ RSS h√≠rek friss√≠t√©se: {datetime.now().strftime('%H:%M:%S')}")
    # Itt lehetne RSS cache friss√≠t√©s, de most m√©g nincs k√ºl√∂n implement√°lva

def fetch_and_analyze():
    """Teljes elemz√©s √∫j cikkekkel (2 √≥r√°nk√©nt)"""
    fetch_and_process_news()

# RSS friss√≠t√©s: 30 percenk√©nt
schedule.every(30).minutes.do(fetch_rss_only)

# AI elemz√©s: 2 √≥r√°nk√©nt  
schedule.every(2).hours.do(fetch_and_analyze)

# Els≈ë futtat√°s h√°tt√©rsz√°lban 2 m√°sodperc m√∫lva
def delayed_first_run():
    """K√©sleltetett els≈ë futtat√°s - csak ha nincs friss adat"""
    time.sleep(2)
    try:
        test_mode_text = '(TESZT M√ìD)' if TEST_MODE else ''
    except NameError:
        test_mode_text = ''
    
    # Ellen≈ërizz√ºk van-e m√°r friss adat az adatb√°zisban
    if is_database_available():
        try:
            articles = db_manager.get_latest_articles(5)
            if articles:
                print(f"\nüíæ {len(articles)} cikk tal√°lhat√≥ az adatb√°zisban - els≈ë feldolgoz√°s kihagy√°sa")
                return
        except Exception as e:
            print(f"\n‚ö†Ô∏è Adatb√°zis ellen≈ërz√©si hiba: {e}")
    
    print(f"\nüöÄ Els≈ë h√≠rek bet√∂lt√©se indul... {test_mode_text}")
    fetch_and_process_news()

# Els≈ë futtat√°s h√°tt√©rsz√°lban
first_run_thread = threading.Thread(target=delayed_first_run, daemon=True)
first_run_thread.start()

# √útemez≈ë ind√≠t√°sa h√°tt√©rsz√°lon
scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
scheduler_thread.start()

@app.route('/')
def index():
    """F≈ëoldal"""
    return render_template('index.html', data=newsletter_data)

@app.route('/api/articles')
def get_articles():
    """API v√©gpont a cikkek lek√©r√©s√©hez"""
    if is_database_available():
        # ADATB√ÅZISB√ìL TOP 30-AT BET√ñLT√úNK (fontoss√°g szerint)
        articles = db_manager.get_latest_articles(30)
        briefing = db_manager.get_latest_executive_briefing()
        
        # FRISS√çTJ√úK A NEWSLETTER_DATA-T IS
        newsletter_data['articles'] = articles
        newsletter_data['executive_briefing'] = briefing['content'] if briefing else "Nincs vezet≈ëi √∂sszefoglal√≥"
        newsletter_data['last_update'] = briefing['created_at'] if briefing else None
        
        return jsonify({
            'articles': articles,
            'executive_briefing': briefing['content'] if briefing else "Nincs vezet≈ëi √∂sszefoglal√≥",
            'last_update': briefing['created_at'] if briefing else None,
            'processing_status': newsletter_data.get('processing_status', 'idle')
        })
    else:
        # Fallback: mem√≥ria m√≥d
        return jsonify(newsletter_data)

@app.route('/api/refresh', methods=['POST'])
def refresh_articles():
    """Manu√°lis friss√≠t√©s"""
    if newsletter_data.get('processing_status') == 'processing':
        return jsonify({'success': False, 'message': 'Feldolgoz√°s m√°r folyamatban...'})
    
    # √öreset√ºnk mindent a duplik√°ci√≥ elker√ºl√©s√©re
    newsletter_data['articles'] = []
    newsletter_data['executive_briefing'] = ''
    
    fetch_and_process_news()
    return jsonify({'success': True, 'message': 'H√≠rek friss√≠tve'})

@app.route('/api/rss-sources')
def get_rss_sources():
    """RSS forr√°sok √©s cikkeik VAL√ìS IDEJ≈∞ lek√©r√©se"""
    sources_with_articles = []
    
    for source in ECONOMIC_SOURCES:
        try:
            # Val√≥s id≈ëben lek√©rj√ºk az RSS feed-et
            feed = feedparser.parse(source['url'])
            recent_articles = []
            
            for entry in feed.entries[:3]:  # Max 3 legfrissebb cikk
                title = entry.get('title', 'Nincs c√≠m')
                link = entry.get('link', '')
                description = entry.get('summary', entry.get('description', ''))
                
                # Publik√°l√°si id≈ë
                pub_date = None
                if hasattr(entry, 'published_parsed'):
                    pub_date = datetime(*entry.published_parsed[:6])
                elif hasattr(entry, 'updated_parsed'):
                    pub_date = datetime(*entry.updated_parsed[:6])
                else:
                    pub_date = datetime.now()
                
                recent_articles.append({
                    'title': title,
                    'link': link,
                    'pub_date': pub_date.isoformat(),
                    'description': description[:150] + '...' if description else ''
                })
            
            source_info = {
                'name': source['name'],
                'url': source['url'],
                'category': source['category'],
                'articles': recent_articles
            }
            sources_with_articles.append(source_info)
            
        except Exception as e:
            print(f"‚ùå RSS lek√©r√©si hiba {source['name']}: {e}")
            # Fallback √ºres cikkekkel
            source_info = {
                'name': source['name'],
                'url': source['url'], 
                'category': source['category'],
                'articles': []
            }
            sources_with_articles.append(source_info)
    
    return jsonify({'sources': sources_with_articles})

@app.route('/api/test-refresh', methods=['POST'])
def test_refresh():
    """Gyors teszt friss√≠t√©s"""
    global TEST_MODE
    TEST_MODE = True
    
    if newsletter_data.get('processing_status') == 'processing':
        return jsonify({'success': False, 'message': 'Feldolgoz√°s m√°r folyamatban...'})
    
    # √öreset√ºnk mindent
    newsletter_data['articles'] = []
    newsletter_data['executive_briefing'] = ''
    
    fetch_and_process_news()
    return jsonify({'success': True, 'message': 'Teszt friss√≠t√©s elind√≠tva (3 forr√°s, 3 cikk)'})

@app.route('/api/cleanup', methods=['POST'])
def cleanup_database():
    """R√©gi cikkek takar√≠t√°sa"""
    if not is_database_available():
        return jsonify({'success': False, 'message': 'Adatb√°zis nem el√©rhet≈ë'})
    
    data = request.get_json() or {}
    days = int(data.get('days', 30))
    deleted = db_manager.cleanup_old_articles(days)
    return jsonify({'success': True, 'message': f'{deleted} r√©gi cikk t√∂r√∂lve'})

@app.route('/api/search')
def search_articles():
    """Keres√©s a cikkekben"""
    if not is_database_available():
        return jsonify({'success': False, 'message': 'Adatb√°zis nem el√©rhet≈ë'})
    
    query = request.args.get('q', '').strip()
    if not query or len(query) < 2:
        return jsonify({'success': False, 'message': 'Minimum 2 karakter sz√ºks√©ges'})
    
    # Keres√©s az √∂sszes cikkben (nem csak a top 30-ban!)
    all_articles = db_manager.get_latest_articles(1000)
    results = []
    
    query_lower = query.lower()
    for article in all_articles:
        # Keres√©s c√≠mben, √∂sszefoglal√≥ban, forr√°sban
        title = (article.get('title', '') or '').lower()
        summary = (article.get('executive_summary', '') or '').lower()
        source = (article.get('source', '') or '').lower()
        
        if (query_lower in title or 
            query_lower in summary or 
            query_lower in source):
            results.append(article)
    
    return jsonify({
        'success': True,
        'query': query,
        'results': results[:50],  # Max 50 tal√°lat
        'total': len(results)
    })

@app.route('/api/db-status')
def database_status():
    """Adatb√°zis √°llapot"""
    if is_database_available():
        article_count = len(db_manager.get_latest_articles(1000))
        briefing = db_manager.get_latest_executive_briefing()
        return jsonify({
            'database_available': True,
            'article_count': article_count,
            'last_briefing': briefing['created_at'] if briefing else None
        })
    else:
        return jsonify({'database_available': False})

@app.route('/api/export-pdf')
def export_pdf():
    """PDF export - Korm√°nyzati jelent√©s"""
    if not is_database_available():
        return jsonify({'success': False, 'message': 'Adatb√°zis nem el√©rhet≈ë'})
    
    try:
        # Adatok lek√©r√©se
        articles = db_manager.get_latest_articles(30)
        briefing = db_manager.get_latest_executive_briefing()
        
        # HTML template gener√°l√°sa
        html_content = f"""
        <!DOCTYPE html>
        <html lang="hu">
        <head>
            <meta charset="UTF-8">
            <title>Korm√°nyzati K√ºlgazdas√°gi Szemle</title>
            <style>
                body {{ font-family: 'Arial', sans-serif; margin: 0; padding: 20px; line-height: 1.4; }}
                .header {{ text-align: center; margin-bottom: 30px; border-bottom: 2px solid #1a237e; padding-bottom: 20px; }}
                .header h1 {{ color: #1a237e; font-size: 28px; margin: 0; }}
                .header .date {{ color: #666; font-size: 14px; margin-top: 10px; }}
                .executive-summary {{ background: #f8f9fa; padding: 20px; margin-bottom: 30px; border-left: 4px solid #1a237e; }}
                .executive-summary h2 {{ color: #1a237e; font-size: 20px; margin-top: 0; }}
                .articles-section h2 {{ color: #1a237e; font-size: 18px; margin-bottom: 20px; border-bottom: 1px solid #ddd; padding-bottom: 10px; }}
                .article {{ margin-bottom: 25px; padding: 15px; border: 1px solid #e0e0e0; page-break-inside: avoid; }}
                .article-title {{ font-size: 16px; font-weight: bold; color: #1a237e; margin-bottom: 8px; }}
                .article-meta {{ font-size: 12px; color: #666; margin-bottom: 10px; }}
                .article-summary {{ font-size: 14px; margin-bottom: 10px; }}
                .analysis-section {{ margin-top: 15px; }}
                .analysis-section h4 {{ color: #444; font-size: 14px; margin-bottom: 8px; }}
                .analysis-list {{ font-size: 12px; margin-left: 15px; }}
                .importance-badge {{ background: #e3f2fd; color: #1565c0; padding: 2px 8px; border-radius: 10px; font-size: 11px; }}
                .urgency-badge {{ background: #fff3e0; color: #e65100; padding: 2px 8px; border-radius: 10px; font-size: 11px; }}
                .footer {{ margin-top: 30px; text-align: center; font-size: 12px; color: #666; border-top: 1px solid #ddd; padding-top: 15px; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>üèõÔ∏è Korm√°nyzati K√ºlgazdas√°gi Szemle</h1>
                <div class="date">Gener√°lva: {datetime.now().strftime('%Y. %m. %d. %H:%M')}</div>
            </div>
        """
        
        # Vezet≈ëi √∂sszefoglal√≥
        if briefing:
            html_content += f"""
            <div class="executive-summary">
                <h2>üìã Vezet≈ëi √ñsszefoglal√≥</h2>
                {briefing['content']}
            </div>
            """
        
        # R√©szletes elemz√©sek
        html_content += """
            <div class="articles-section">
                <h2>üìä R√©szletes Elemz√©sek</h2>
        """
        
        for i, article in enumerate(articles, 1):
            analysis = article.get('full_analysis', {})
            html_content += f"""
                <div class="article">
                    <div class="article-title">{i}. {article.get('title', 'Nincs c√≠m')}</div>
                    <div class="article-meta">
                        <span class="importance-badge">Fontoss√°g: {article.get('importance_score', 'N/A')}/10</span>
                        <span class="urgency-badge">{article.get('urgency', 'N/A')}</span>
                        | Forr√°s: {article.get('source', 'N/A')} | {article.get('pub_date', 'N/A')[:10]}
                    </div>
                    <div class="article-summary">{article.get('executive_summary', 'Nincs √∂sszefoglal√≥')}</div>
            """
            
            # Makrogazdas√°gi hat√°sok
            if analysis.get('macro_impacts'):
                macro = analysis['macro_impacts']
                html_content += """
                    <div class="analysis-section">
                        <h4>üá≠üá∫ Magyarorsz√°gi Makrogazdas√°gi Hat√°sok</h4>
                        <div class="analysis-list">
                """
                for key, value in macro.items():
                    if value and value != 'N/A':
                        # TELJES SZ√ñVEG, nem lev√°gva!
                        html_content += f"<div style='margin-bottom: 8px;'><strong>{key.replace('_', ' ').title()}:</strong> {value}</div>"
                html_content += "</div></div>"
            
            # Szektor√°lis elemz√©s
            if analysis.get('sectoral_analysis'):
                sectoral = analysis['sectoral_analysis']
                html_content += """
                    <div class="analysis-section">
                        <h4>üè≠ Szektor√°lis Elemz√©s</h4>
                        <div class="analysis-list">
                """
                if sectoral.get('affected_sectors'):
                    html_content += f"<div><strong>√ârintett szektorok:</strong> {', '.join(sectoral['affected_sectors'])}</div>"
                if sectoral.get('employment_impact'):
                    # TELJES SZ√ñVEG, nem lev√°gva!
                    html_content += f"<div style='margin-bottom: 8px;'><strong>Munkaer≈ëpiaci hat√°s:</strong> {sectoral['employment_impact']}</div>"
                html_content += "</div></div>"
            
            html_content += "</div>"
        
        html_content += """
            </div>
            <div class="footer">
                <p>Korm√°nyzati K√ºlgazdas√°gi Szemle - Automatikusan gener√°lt jelent√©s</p>
                <p>ü§ñ Generated with Claude Code | Co-Authored-By: Claude</p>
            </div>
        </body>
        </html>
        """
        
        # PDF gener√°l√°s
        filename = f"Kormanyzati_Szemle_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf"
        
        # Temp f√°jl l√©trehoz√°sa
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            # Production-ben nincs PDF
            return jsonify({'success': False, 'message': 'PDF export nem el√©rhet≈ë production k√∂rnyezetben. Haszn√°ld lok√°lisan!'})
            
            return send_file(
                tmp_file.name,
                as_attachment=True,
                download_name=filename,
                mimetype='application/pdf'
            )
            
    except Exception as e:
        print(f"‚ùå PDF export hiba: {{e}}")
        return jsonify({{'success': False, 'message': f'PDF gener√°l√°si hiba: {{str(e)}}'}})

if __name__ == '__main__':
    print(f"\nüîß Teszt m√≥d: {'BE' if TEST_MODE else 'KI'}")
    print(f"üíæ Adatb√°zis: {'PostgreSQL' if is_database_available() else 'Mem√≥ria m√≥d'}")
    print("\nüîÑ API Endpoints:")
    print("  POST /api/refresh - Teljes friss√≠t√©s")
    print("  POST /api/test-refresh - Gyors teszt friss√≠t√©s (3 forr√°s, 3 cikk)")
    print("  POST /api/cleanup - R√©gi cikkek takar√≠t√°sa")
    print("  GET /api/search?q=keyword - Keres√©s cikkekben")
    print("  GET /api/export-pdf - PDF let√∂lt√©s")
    print("  GET /api/db-status - Adatb√°zis √°llapot")
    print("\nüåç Environment variables:")
    print("  TEST_MODE=true - Gyors teszt m√≥d")
    print("  DATABASE_URL=postgresql://... - PostgreSQL kapcsolat\n")
    
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)